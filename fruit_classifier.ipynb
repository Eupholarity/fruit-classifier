{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58_2RALdC3o"
      },
      "source": [
        "#Fruit Classifier Project\n",
        "\n",
        "**Project Goal:** To create a classification model that can accurately distinguish between Bananas, Grapes, and Apples.\n",
        "---\n",
        "## 1. Data Setup and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "p0QdcqRAcdMS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Loaded and Initial Cleanup Performed:\n",
            "   target         color    size     weight\n",
            "0   grape        Yellow    Tiny   8.303385\n",
            "1   apple          Pink  Largee  80.976370\n",
            "2  banana   Pale Yellow   Large  74.615192\n",
            "3   grape           Red    Tiny   6.924070\n",
            "4  banana  Creamy White  Largee  82.002542\n",
            "\n",
            "Data Status:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   target  200 non-null    object \n",
            " 1   color   200 non-null    object \n",
            " 2   size    200 non-null    object \n",
            " 3   weight  200 non-null    float64\n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 6.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# Necessary tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "# Load the data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(r\"C:\\Users\\JJE4FE\\Desktop\\fruit_data.xlsx\")\n",
        "df.head()\n",
        "\n",
        "# Drop the unnecessary index column\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Fix the error in the 'weight' column and rename target column\n",
        "df['weight'] = df['weight'].astype(str).str.replace('e', '', regex=False)\n",
        "df['weight'] = pd.to_numeric(df['weight'], errors='coerce')\n",
        "df = df.rename(columns={'fruit_type': 'target'})\n",
        "\n",
        "# Show the first 5 rows\n",
        "print(\"Data Loaded and Initial Cleanup Performed:\")\n",
        "print(df.head())\n",
        "print(\"\\nData Status:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5rVXSugdzXB"
      },
      "source": [
        "## Data Preparation: Final Cleaning and Encoding\n",
        "\n",
        "We perform final cleanup by fixing inconsistencies in the categorical columns and then prepare the data for the models. This involves:\n",
        "1.  Consolidating inconsistent labels (`Largee` -> `Large`).\n",
        "2.  One-Hot Encoding categorical features (`color`, `size`) into numbers.\n",
        "3.  Label Encoding the target variable (`target`) into 0, 1, 2.\n",
        "4.  Scaling the `weight` column (for Logistic Regression)\n",
        "5.  Splitting the data into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "_DlnOBZud9XF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows after removing duplicates: 177\n",
            "\n",
            "Target classes encoded to: ['apple' 'banana' 'grape']\n",
            "Train/Test split completed. Train size: 141\n",
            "\n",
            "Data preparation finished. Data is scaled and split.\n"
          ]
        }
      ],
      "source": [
        "# Each alphabet lowercased\n",
        "for col in ['target', 'color', 'size']:\n",
        "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
        "\n",
        "# Fix inconsistencies of naming\n",
        "df['size'] = df['size'].replace({'largee': 'large', 'tiny': 'small'})\n",
        "df['color'] = df['color'].replace({'yellow1': 'yellow'})\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Total rows after removing duplicates: {len(df)}\\n\")\n",
        "\n",
        "# Separation of Features (X) and Target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Target Encoding (converts apple/banana/grape to 0/1/2)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "target_classes = le.classes_\n",
        "print(f\"Target classes encoded to: {target_classes}\")\n",
        "\n",
        "# One-Hot Encoding for features\n",
        "X_encoded = pd.get_dummies(X, columns=['color', 'size'], drop_first=True, dtype=int)\n",
        "\n",
        "# Split the data (20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "print(f\"Train/Test split completed. Train size: {len(X_train)}\\n\")\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "# Find the weight column index for simple scaling\n",
        "weight_col = X_train.columns.get_loc('weight')\n",
        "\n",
        "# Scale the weight column in both train and test sets\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "# Fit only on training data, then transform both\n",
        "X_train_scaled.iloc[:, weight_col] = scaler.fit_transform(\n",
        "    X_train_scaled.iloc[:, weight_col].values.reshape(-1, 1)\n",
        ")\n",
        "X_test_scaled.iloc[:, weight_col] = scaler.transform(\n",
        "    X_test_scaled.iloc[:, weight_col].values.reshape(-1, 1)\n",
        ")\n",
        "\n",
        "print(\"Data preparation finished. Data is scaled and split.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0u8Xlv4euSP"
      },
      "source": [
        "## 2 Modeling and Analysis\n",
        "\n",
        "We now build the two required models: Logistic Regression (a simple, linear model) and Decision Tree (a non-linear, interpretable model).\n",
        "\n",
        "To show a transparent choice of hyperparameters, we will use a simple method: testing a few different settings (parameters) and choosing the one that performs best on the training data. This is better than just using the defaults."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "U61z2dRxe5NB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning Logistic Regression (C value):\n",
            "  C=0.1   -> F1 Score: 0.7717\n",
            "  C=1.0   -> F1 Score: 0.8261\n",
            "  C=10.0  -> F1 Score: 0.8717\n",
            "\n",
            "Chosen Hyperparameter: C = 10.0 (Transparent Choice)\n",
            "\n",
            "Final Test Set Evaluation (Logistic Regression)\n",
            "Test Accuracy: 0.8888888888888888\n",
            "Test F1 (macro): 0.8931623931623932\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       0.85      0.85      0.85        13\n",
            "      banana       0.83      0.83      0.83        12\n",
            "       grape       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           0.89        36\n",
            "   macro avg       0.89      0.89      0.89        36\n",
            "weighted avg       0.89      0.89      0.89        36\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JJE4FE\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\JJE4FE\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
            "  warnings.warn(\n",
            "C:\\Users\\JJE4FE\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\JJE4FE\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
            "  warnings.warn(\n",
            "C:\\Users\\JJE4FE\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "C:\\Users\\JJE4FE\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "C_values = [0.1, 1.0, 10.0]\n",
        "best_f1 = 0\n",
        "best_C = None\n",
        "best_logreg_model = None\n",
        "\n",
        "print(\"Tuning Logistic Regression (C value):\")\n",
        "for C in C_values:\n",
        "    # Use the SCALED data (X_train_scaled, y_train)\n",
        "    model = LogisticRegression(C=C, random_state=42, multi_class='ovr', solver='liblinear')\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Evaluate performance on the training set\n",
        "    y_pred_train = model.predict(X_train_scaled)\n",
        "    f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
        "\n",
        "    print(f\"  C={C:<5} -> F1 Score: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_C = C\n",
        "        best_logreg_model = model\n",
        "\n",
        "print(f\"\\nChosen Hyperparameter: C = {best_C} (Transparent Choice)\")\n",
        "\n",
        "# We now evaluate the best model on the unseen test data\n",
        "y_pred_logreg = best_logreg_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nFinal Test Set Evaluation (Logistic Regression)\")\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"Test F1 (macro):\", f1_score(y_test, y_pred_logreg, average='macro'))\n",
        "print(\"\\nClassification report:\\n\",\n",
        "      classification_report(y_test, y_pred_logreg, target_names=target_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGhrRSoyhPii"
      },
      "source": [
        "## Decision Tree with Parameter Tuning\n",
        "\n",
        "The Decision Tree classifier is a non-linear model that is generally insensitive to feature scaling, making it a good comparison to Logistic Regression.\n",
        "\n",
        "We will tune the max_depth parameter, which controls the complexity of the tree and prevents overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Ycd_kbeIhsbC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuning Decision Tree (max_depth):\n",
            "  Depth=3  -> F1 Score: 0.8205\n",
            "  Depth=5  -> F1 Score: 0.8917\n",
            "  Depth=7  -> F1 Score: 0.9078\n",
            "  Depth=10 -> F1 Score: 0.9716\n",
            "\n",
            "Chosen Hyperparameter: Max Depth = 10 (Transparent Choice)\n",
            "\n",
            "Final Test Set Evaluation (Decision Tree)\n",
            "Test Accuracy: 0.8055555555555556\n",
            "Test F1 (macro): 0.8133333333333334\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       apple       0.75      0.69      0.72        13\n",
            "      banana       0.69      0.75      0.72        12\n",
            "       grape       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.81      0.81      0.81        36\n",
            "weighted avg       0.81      0.81      0.81        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree Classifier\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "max_depths = [3, 5, 7, 10]\n",
        "best_f1_dt = 0\n",
        "best_depth = None\n",
        "best_dt_model = None\n",
        "\n",
        "print(\"Tuning Decision Tree (max_depth):\")\n",
        "for depth in max_depths:\n",
        "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate performance on the training set\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
        "\n",
        "    print(f\"  Depth={depth:<2} -> F1 Score: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1_dt:\n",
        "        best_f1_dt = f1\n",
        "        best_depth = depth\n",
        "        best_dt_model = model\n",
        "\n",
        "print(f\"\\nChosen Hyperparameter: Max Depth = {best_depth} (Transparent Choice)\")\n",
        "\n",
        "# We now evaluate the best model on the unseen test data\n",
        "y_pred_dt = best_dt_model.predict(X_test)\n",
        "\n",
        "print(\"\\nFinal Test Set Evaluation (Decision Tree)\")\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Test F1 (macro):\", f1_score(y_test, y_pred_dt, average='macro'))\n",
        "print(\"\\nClassification report:\\n\",\n",
        "      classification_report(y_test, y_pred_dt, target_names=target_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m4I3PDYifSV"
      },
      "source": [
        "## 3 Model Performance and Interpretation\n",
        "\n",
        "We now finalize the evaluation of both optimized models using the mandatory ROC-AUC score. Finally, we compare all metrics and draw a conclusion on the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "N6plhlltiiOT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROC-AUC Scores:\n",
            "Logistic Regression: 0.9753\n",
            "Decision Tree:       0.8810\n",
            "\n",
            "Comprehensive Model Performance:\n",
            "                    LogReg Score  DT Score\n",
            "Metric                                    \n",
            "Accuracy                   0.889     0.806\n",
            "F1 Score (Macro)           0.893     0.813\n",
            "ROC-AUC (Weighted)         0.975     0.881\n"
          ]
        }
      ],
      "source": [
        "# Tools for calculating scores and making the table\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Probabilities\n",
        "logreg_probs = best_logreg_model.predict_proba(X_test_scaled)\n",
        "dt_probs = best_dt_model.predict_proba(X_test)\n",
        "\n",
        "# Calculate the ROC-scores\n",
        "logreg_roc_auc = roc_auc_score(y_test, logreg_probs, multi_class='ovr', average='weighted')\n",
        "dt_roc_auc = roc_auc_score(y_test, dt_probs, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(\"ROC-AUC Scores:\")\n",
        "print(f\"Logistic Regression: {logreg_roc_auc:.4f}\")\n",
        "print(f\"Decision Tree:       {dt_roc_auc:.4f}\")\n",
        "\n",
        "# Gather all the final performance metrics into one easy-to-read structure.\n",
        "summary_data = {\n",
        "    'Metric': ['Accuracy', 'F1 Score (Macro)', 'ROC-AUC (Weighted)'],\n",
        "    'LogReg Score': [\n",
        "        accuracy_score(y_test, y_pred_logreg),\n",
        "        f1_score(y_test, y_pred_logreg, average='macro'),\n",
        "        logreg_roc_auc\n",
        "    ],\n",
        "    'DT Score': [\n",
        "        accuracy_score(y_test, y_pred_dt),\n",
        "        f1_score(y_test, y_pred_dt, average='macro'),\n",
        "        dt_roc_auc\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = DataFrame(summary_data).set_index('Metric').round(3) # Final table\n",
        "\n",
        "print(\"\\nComprehensive Model Performance:\")\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j05FpusfjCWJ"
      },
      "source": [
        "## 4 Conclusion and Project Summary\n",
        "\n",
        "### 4.1 Final Model Recommendation\n",
        "\n",
        "The project aimed to develop a classifier to distinguish between apples, bananas, and grapes. Based on a comprehensive evaluation of all required metrics on the unseen test data, the Logistic Regression model is the final recommended classifier.\n",
        "\n",
        "| Model | Accuracy | F1 Score (Macro) | ROC-AUC (Weighted) |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| Logistic Regression | 0.889 | 0.893 | 0.975 |\n",
        "| Decision Tree | 0.806 | 0.813 | 0.881 |\n",
        "\n",
        "The Logistic Regression model, optimized with a C-value of 10.0 and trained on scaled features (which helps distance-based algorithms), performed significantly better across all metrics:\n",
        "\n",
        "* Higher Accuracy: A score of 0.889 means it correctly identified the fruit type nearly 9 out of 10 times.\n",
        "* Superior ROC-AUC: A weighted ROC-AUC of 0.975 is very strong. Since this metric measures the model's ability to rank probabilities, a score this close to 1.0 indicates the model is highly capable of separating the three fruit classes consistently.\n",
        "* Strong F1 Score: The 0.893 F1 score suggests a strong balance between precision (avoiding false positives) and recall (avoiding false negatives) across all three classes.\n",
        "\n",
        "While the Decision Tree model showed high performance on the training data, its performance dropped severely on the test set. This difference between training and test performance indicates overfitting, meaning the model memorized the training data's noise and did not generalize well to new, unseen data.\n",
        "\n",
        "### 4.2 Key Findings and Insights\n",
        "\n",
        "1.  Grapes are Easiest: Both models achieved a perfect 1.00 F1-score for Grapes, suggesting this fruit is clearly distinguishable based on the provided features.\n",
        "2.  Apples and Bananas are Confused: The primary misclassifications occurred between apples and bananas, as suggested by their lower F1 scores (around 0.85). This suggests that their feature distributions (e.g., color, size, or shape) may overlap more than the other classes.\n",
        "3.  Feature Scaling is Crucial: The superior performance of Logistic Regression (a linear model sensitive to feature magnitude) confirms the benefit of data scaling for this classification problem."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
